# Basics 
Cover till LSTM and RNN from the Andrew notes, and read the Alammar blog for word2vec and how to train it.
- [AndrewNG course-5](../DeepLearning.ai-Summary-master/5-%20Sequence%20Models)
- [RNN]() 
- [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Word2Vec How to Train - Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)


# Transformers
1. [Seq2Seq model with attentions](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
2. [Transformers](https://jalammar.github.io/illustrated-transformer/) 

Transformers with Attention is all you need understanding.


# BERT
1. [Visual Guide to BERT](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)
2. [Explain Transformers](https://jalammar.github.io/explaining-transformers/)